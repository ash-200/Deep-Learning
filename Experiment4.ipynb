{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e6arkq0AZC7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f869e0-fd94-4f64-827f-71c40f103fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'microsoft-catsvsdogs-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/microsoft-catsvsdogs-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNyipEkMnxlk",
        "outputId": "3fddeaac-89a1-4aa5-f930-94386f59bc37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PetImages', 'readme[1].txt', 'MSR-LA - 3467.docx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(path, 'PetImages')\n"
      ],
      "metadata": {
        "id": "Mqd_Ewj_oESj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "dst_path = '/content/my_dataset'\n",
        "if os.path.exists(dst_path):\n",
        "    shutil.rmtree(dst_path)\n",
        "shutil.copytree(path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tJIOSanrpAuk",
        "outputId": "e62be701-572f-407d-99f5-c922019fce44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/my_dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Define the transformation pipeline\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize to a consistent size\n",
        "    transforms.ToTensor(),           # Convert to tensor [0, 1]\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Standard normalization\n",
        "])"
      ],
      "metadata": {
        "id": "GQUoquvWnA3O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "data_dir = '/content/my_dataset/PetImages' # or your specific path\n",
        "categories = ['Cat', 'Dog']\n",
        "\n",
        "for category in categories:\n",
        "    folder_path = os.path.join(data_dir, category)\n",
        "    removed_count = 0\n",
        "\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        try:\n",
        "            # Try to open the image and verify it\n",
        "            with Image.open(img_path) as img:\n",
        "                img.verify()\n",
        "        except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
        "            # If PIL can't open it, delete it\n",
        "            os.remove(img_path)\n",
        "            removed_count += 1\n",
        "\n",
        "    print(f\"Removed {removed_count} corrupted images from {category} folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y2vndSH7RU7",
        "outputId": "69fc1420-1763-43c1-9887-eca3943df9f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 2 corrupted images from Cat folder.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 2 corrupted images from Dog folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'path' variable comes from your kagglehub download\n",
        "\n",
        "data_dir = os.path.join(dst_path, 'PetImages')\n",
        "\n",
        "# Load the dataset\n",
        "full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n",
        "\n",
        "# Split into Train and Validation (80/20 split)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Total images: {len(full_dataset)}\")\n",
        "print(f\"Classes found: {full_dataset.classes}\")"
      ],
      "metadata": {
        "id": "LgAqygZmnQUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b5ec51-23a8-4305-8d73-e9ae4d179b9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 24998\n",
            "Classes found: ['Cat', 'Dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check a batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"Batch shape: {images.shape}\") # Should be [32, 3, 128, 128]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFzlkopMtsCw",
        "outputId": "867a4f1e-a8d2-48bc-dba0-376d591ad889"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.xavier_uniform_(self.conv1.weight) # Xavier uniform for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)    # Xavier uniform for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN().to('cuda') # Use GPU if available\n",
        "\n",
        "# print(\"Sample of initialized conv1 weights (first row):\")\n",
        "# print(model.conv1.weight[0, 0, :, :])\n",
        "# print(\"Sample of initialized conv1 bias:\")\n",
        "# print(model.conv1.bias)\n"
      ],
      "metadata": {
        "id": "FgNeKUoy4Pqz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "30eXqSgj4Plt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H2jHeND4Per",
        "outputId": "4dfd4f16-2a6e-4ff8-8180-2f62de2e98da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7820382914066315\n",
            "Epoch 2, Loss: 0.505348783826828\n",
            "Epoch 3, Loss: 0.4372052148103714\n",
            "Epoch 4, Loss: 0.38380809634923935\n",
            "Epoch 5, Loss: 0.33164840748310087\n",
            "Epoch 6, Loss: 0.28701964209079744\n",
            "Epoch 7, Loss: 0.24679675822257996\n",
            "Epoch 8, Loss: 0.21481974304318427\n",
            "Epoch 9, Loss: 0.1835541669487953\n",
            "Epoch 10, Loss: 0.16260048270821573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSahToFn4PE7",
        "outputId": "88841111-1c5a-4ff9-e159-a7e9590da792"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set: 69.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cats_dogs_model_1.pth')\n",
        "print(\"Model saved as cats_dogs_model_1.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYfzIqyG8v2k",
        "outputId": "7c092c9f-c945-4ba3-d84a-260cea70c070"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as cats_dogs_model_1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OY8Dfp724MXo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.kaiming_normal_(self.conv1.weight) # kaiming_normal_ for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)    # Kaiming normal for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN2().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7jO6_B54WhJ",
        "outputId": "1983d5f7-2a57-49a2-8101-c197ae5ef957"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.2179470736503601\n",
            "Epoch 2, Loss: 1.217990549659729\n",
            "Epoch 3, Loss: 1.2179853203773499\n",
            "Epoch 4, Loss: 1.2179677515029907\n",
            "Epoch 5, Loss: 1.2179656868934632\n",
            "Epoch 6, Loss: 1.218007322216034\n",
            "Epoch 7, Loss: 1.2179712107658387\n",
            "Epoch 8, Loss: 1.2179925091743469\n",
            "Epoch 9, Loss: 1.217990859222412\n",
            "Epoch 10, Loss: 1.2179740591049195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQwLzUIo5M0j",
        "outputId": "bd06cf5a-775d-4cca-b1a6-af7e0f0f8f99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set: 47.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cats_dogs_model_2.pth')\n",
        "print(\"Model saved as cats_dogs_model_2.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nFKNatz6CKB",
        "outputId": "d4f4201a-78da-48ed-ecf5-6d64703e0e63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as cats_dogs_model_2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWMtjpHp6FXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.uniform_(self.conv1.weight) # random for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.uniform_(self.fc1.weight)    # random for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN3().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), 'cats_dogs_model_3.pth')\n",
        "print(\"Model saved as cats_dogs_model_3.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eS1WcO46qpR",
        "outputId": "23e3d44d-2ef9-4ec4-a7ce-c28089b663fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 492.3087629394531\n",
            "Epoch 2, Loss: 492.3176787597656\n",
            "Epoch 3, Loss: 492.31218322753904\n",
            "Epoch 4, Loss: 492.31887907714844\n",
            "Epoch 5, Loss: 492.3440726074219\n",
            "Epoch 6, Loss: 492.3090771240234\n",
            "Epoch 7, Loss: 492.316772265625\n",
            "Epoch 8, Loss: 492.30397082519534\n",
            "Epoch 9, Loss: 492.310807421875\n",
            "Epoch 10, Loss: 492.32620485839846\n",
            "Accuracy on validation set: 48.14%\n",
            "Model saved as cats_dogs_model_3.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.xavier_uniform_(self.conv1.weight) # Xavier uniform for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)    # Xavier uniform for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.tanh(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN3().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), 'cats_dogs_model_4.pth')\n",
        "print(\"Model saved as cats_dogs_model_4.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk-Zde2fBaV1",
        "outputId": "22101c2a-f892-4602-a125-c53699a04487"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7716261992454528\n",
            "Epoch 2, Loss: 0.7716352178573609\n",
            "Epoch 3, Loss: 0.7716429697036743\n",
            "Epoch 4, Loss: 0.7716566767692566\n",
            "Epoch 5, Loss: 0.7716396781921386\n",
            "Epoch 6, Loss: 0.771645639514923\n",
            "Epoch 7, Loss: 0.7716466102600098\n",
            "Epoch 8, Loss: 0.7716590131759643\n",
            "Epoch 9, Loss: 0.7716462043762207\n",
            "Epoch 10, Loss: 0.7716323496818542\n",
            "Accuracy on validation set: 48.96%\n",
            "Model saved as cats_dogs_model_3.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cats_dogs_model_4.pth')"
      ],
      "metadata": {
        "id": "fpS_SxzfFNM8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.xavier_uniform_(self.conv1.weight) # Xavier uniform for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)    # Xavier uniform for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN3().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), 'cats_dogs_model_5.pth')\n",
        "print(\"Model saved as cats_dogs_model_5.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX2SApyaCRib",
        "outputId": "7ffdd242-af20-4e71-d11b-0c25155e12e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8889616750240326\n",
            "Epoch 2, Loss: 0.8889877446174621\n",
            "Epoch 3, Loss: 0.8889830102920532\n",
            "Epoch 4, Loss: 0.8889696611404418\n",
            "Epoch 5, Loss: 0.8889585578918457\n",
            "Epoch 6, Loss: 0.8889765306949615\n",
            "Epoch 7, Loss: 0.888968433380127\n",
            "Epoch 8, Loss: 0.8889755222320557\n",
            "Epoch 9, Loss: 0.8889608957290649\n",
            "Epoch 10, Loss: 0.888961439037323\n",
            "Accuracy on validation set: 50.14%\n",
            "Model saved as cats_dogs_model_5.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.xavier_uniform_(self.conv1.weight) # Xavier uniform for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)    # Xavier uniform for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN3().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), 'cats_dogs_model_6.pth')\n",
        "print(\"Model saved as cats_dogs_model_6.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bV0jBlCvz4",
        "outputId": "da100349-586e-400a-dfd2-6a5bcd080e39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8123146061897277\n",
            "Epoch 2, Loss: 0.8122840463638306\n",
            "Epoch 3, Loss: 0.812307015132904\n",
            "Epoch 4, Loss: 0.8123001019477845\n",
            "Epoch 5, Loss: 0.8122790049552917\n",
            "Epoch 6, Loss: 0.8122962166786194\n",
            "Epoch 7, Loss: 0.8122986666679383\n",
            "Epoch 8, Loss: 0.8122985091209411\n",
            "Epoch 9, Loss: 0.8122832621574402\n",
            "Epoch 10, Loss: 0.8122864789009094\n",
            "Accuracy on validation set: 50.36%\n",
            "Model saved as cats_dogs_model_6.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(SimpleCNN, self) to super()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 64 * 64, 2) # Assuming 128x128 input\n",
        "\n",
        "        # Custom weight initialization\n",
        "        nn.init.xavier_uniform_(self.conv1.weight) # Xavier uniform for convolutional weights\n",
        "        nn.init.constant_(self.conv1.bias, 0.01)   # Small constant for convolutional biases\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)    # Xavier uniform for fully connected weights\n",
        "        nn.init.constant_(self.fc1.bias, 0)        # Zeros for fully connected biases\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 64 * 64)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN3().to('cuda')\n",
        "\n",
        "\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for speed/memory\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(), 'cats_dogs_model_7.pth')\n",
        "print(\"Model saved as cats_dogs_model_7.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aTQN27tC3ra",
        "outputId": "035ef43c-e80f-44a8-8a14-edad679785ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9230966591835021\n",
            "Epoch 2, Loss: 0.9230959101676941\n",
            "Epoch 3, Loss: 0.923071548318863\n",
            "Epoch 4, Loss: 0.9230881919384003\n",
            "Epoch 5, Loss: 0.9230868430137634\n",
            "Epoch 6, Loss: 0.9231089612960816\n",
            "Epoch 7, Loss: 0.9231427976608276\n",
            "Epoch 8, Loss: 0.9230854653358459\n",
            "Epoch 9, Loss: 0.9230904733657836\n",
            "Epoch 10, Loss: 0.9231180364608764\n",
            "Accuracy on validation set: 50.40%\n",
            "Model saved as cats_dogs_model_7.pth\n"
          ]
        }
      ]
    }
  ]
}