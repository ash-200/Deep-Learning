{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nauLo5Ep0Do0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(\"/content/poems-100.csv\")\n",
        "\n",
        "# Ignore first row and extract poems\n",
        "poems = df.iloc[1:, 0].astype(str).tolist()\n",
        "\n",
        "# Combine all poems into one text corpus\n",
        "text_data = \" \".join(poems).lower()\n",
        "\n",
        "print(\"Number of poems:\", len(poems))\n",
        "print(\"Sample text:\\n\", text_data[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDoDkgA30Iqe",
        "outputId": "fae82e5b-9930-4650-b46d-d596ca6f8dac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of poems: 99\n",
            "Sample text:\n",
            " the rose is red,\n",
            "the violet's blue,\n",
            "sugar is sweet,\n",
            "and so are you. how do i love thee? let me count the ways.\n",
            "i love thee to the depth and breadth and height\n",
            "my soul can reach, when feeling out of sight\n",
            "for the ends of being and ideal grace.\n",
            "i love thee to the level of every day's\n",
            "most quiet need, by sun and candle-light.\n",
            "i love thee freely, as men strive for right.\n",
            "i love thee purely, as they turn from praise.\n",
            "i love thee with the passion put to use\n",
            "in my old griefs, and with my childhood's fa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple whitespace tokenization\n",
        "tokens = text_data.split()\n",
        "\n",
        "# Build vocabulary\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Word to index mapping\n",
        "word2idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx2word = {i: word for word, i in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"Sample vocab words:\", vocab[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zXusK_0IoE",
        "outputId": "2955c545-f239-4cc2-eae2-0ca1d080b125"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6965\n",
            "Sample vocab words: ['\"he', '\"most', '\"oh,', \"'greatly\", \"'neath\", \"'our\", \"'s\", \"'tis\", \"'twas\", \"'twere\", \"'twill\", \"('tis\", '(1)', '(and', '(as', '(behind', '(come', '(even', '(floating', '(for']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h = np.zeros((self.hidden_size, 1))\n",
        "        outputs = []\n",
        "\n",
        "        for x in inputs:\n",
        "            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n",
        "            y = np.dot(self.Why, h) + self.by\n",
        "            outputs.append(y)\n",
        "\n",
        "        return outputs, h"
      ],
      "metadata": {
        "id": "vXRq_pYU0IlW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "\n",
        "def create_sequences(tokens, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(tokens) - seq_length):\n",
        "        seq = tokens[i:i+seq_length]\n",
        "        target = tokens[i+seq_length]\n",
        "        sequences.append((seq, target))\n",
        "    return sequences\n",
        "\n",
        "sequences = create_sequences(tokens, sequence_length)\n",
        "print(\"Total sequences:\", len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDpgvoBe0Ii0",
        "outputId": "ae3fdc24-0f61-4beb-e884-d28e603153d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences: 24623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(word, vocab_size):\n",
        "    vec = np.zeros(vocab_size)\n",
        "    vec[word2idx[word]] = 1\n",
        "    return vec"
      ],
      "metadata": {
        "id": "6AO_I5pJ0Igi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "dataset_onehot = OneHotDataset(sequences)\n",
        "loader_onehot = torch.utils.data.DataLoader(dataset_onehot, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "FK99dXZT0IeB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN_OneHot, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "f1qGNPXG0Ib0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQmm4Psm4GAL",
        "outputId": "f0ffb3a0-2fd8-46b3-f1f8-ffe657cd2f84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_onehot = RNN_OneHot(vocab_size, 128, vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_onehot.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_onehot:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_onehot(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_onehot):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjXhkOw40IZH",
        "outputId": "e308f27f-950a-42c1-d4f5-c477ba00c563"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.2617\n",
            "Epoch 2, Loss: 6.4292\n",
            "Epoch 3, Loss: 5.7151\n",
            "Epoch 4, Loss: 4.8640\n",
            "Epoch 5, Loss: 3.9538\n",
            "Epoch 6, Loss: 3.1009\n",
            "Epoch 7, Loss: 2.3473\n",
            "Epoch 8, Loss: 1.7155\n",
            "Epoch 9, Loss: 1.2254\n",
            "Epoch 10, Loss: 0.8763\n",
            "Training Time: 1228.0945873260498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_onehot(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor([x], dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_onehot(model_onehot, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_decrudZ0IWt",
        "outputId": "c9dbad71-6540-4bf5-af95-6ec88e6d9559"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was the idols, and once and the streets of his bludgeons and rapt that i could the woods of now, i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IndexedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "        x = torch.tensor([word2idx[word] for word in seq], dtype=torch.long)\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "dataset_embed = IndexedDataset(sequences)\n",
        "loader_embed = torch.utils.data.DataLoader(dataset_embed, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "BSp8Xf0d0IS4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super(RNN_Embedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "H_OlJucT0IQf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = RNN_Embedding(vocab_size, 100, 128).to(device)\n",
        "optimizer = optim.Adam(model_embed.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_embed:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_embed(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_embed):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqnxHlLV0rR5",
        "outputId": "a1f1aeda-c64f-40f0-bf4e-dfb7568183d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.3406\n",
            "Epoch 2, Loss: 6.4441\n",
            "Epoch 3, Loss: 5.9230\n",
            "Epoch 4, Loss: 5.4002\n",
            "Epoch 5, Loss: 4.8741\n",
            "Epoch 6, Loss: 4.3489\n",
            "Epoch 7, Loss: 3.8368\n",
            "Epoch 8, Loss: 3.3542\n",
            "Epoch 9, Loss: 2.9188\n",
            "Epoch 10, Loss: 2.5318\n",
            "Training Time: 12.140402793884277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_embedding(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = torch.tensor([[word2idx[word] for word in seq]], dtype=torch.long).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_embedding(model_embed, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og5X3YMu0rKh",
        "outputId": "3eab81fa-eeae-4f77-9d67-b53526499ba0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was never made; the same waits in the race, under the policeman travels his beat, the gate-keeper marks of all the\n"
          ]
        }
      ]
    }
  ]
}